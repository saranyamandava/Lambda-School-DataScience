{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week9_ Neural Networks Sprint Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "aD8Yb0P8D04e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks Coding Challenge\n",
        "\n",
        "Objectives:\n",
        "  * Write a simple three layer network\n",
        "  * Compute forward propagation for a new sample in three layer network\n",
        "  * Compute backward propagation in the same network\n",
        "  * Use MLPClassifier to train and test a dataset\n",
        "\n",
        "### Background\n",
        "\n",
        "Other than the MLPClassifier objective, you will be working with this neural net during this coding challenge:\n",
        "\n",
        "![Simple Neural Net](https://www.lucidchart.com/publicSegments/view/a5b0773e-7165-450d-99fc-7089891e099a/image.png)"
      ]
    },
    {
      "metadata": {
        "id": "9JrCk2HEPwoI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Write a simple three layer network\n",
        "\n",
        "Create variables to store weights and biases for the above network. Initialize each with $0.5$."
      ]
    },
    {
      "metadata": {
        "id": "5UeD3N5_PwCF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "syn = [0.5,0.5,0.5]\n",
        "b = [0.5,0.5,0.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSfpHHfJFPc5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Compute forward propagation for a new sample in three layer network\n",
        "\n",
        "Write a function `feed_forward` that takes a new sample $x$ and calculates $\\hat{y}$ via forward propagation."
      ]
    },
    {
      "metadata": {
        "id": "oI260RxPrUV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = 4\n",
        "x2 = 0.5\n",
        "x3 = 0.125\n",
        "y1 = 0\n",
        "y2 = 1\n",
        "y3 = 1\n",
        "\n",
        "# sigmoid function\n",
        "\n",
        "def nonlin(x,deriv=False): \n",
        "  if(deriv==True):\n",
        "     return x*(1-x)\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3K306_pFUQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "904574d4-3e72-4aeb-a5d2-16cc3cc4d677"
      },
      "cell_type": "code",
      "source": [
        "# CODE\n",
        "\n",
        "\n",
        "def feed_forward(X,y,syn,b):\n",
        "  # seed random numbers to make calculation\n",
        "  np.random.seed(42) \n",
        "\n",
        "  # forward propagation\n",
        "  h1 = nonlin(np.dot(X,syn[0])+b[0])\n",
        "  h2 = nonlin(np.dot(h1,syn[1])+b[1])\n",
        "  y_hat = nonlin(np.dot(h2,syn[2])+b[2])\n",
        "  print (y_hat)\n",
        "  return y_hat\n",
        "\n",
        "# TEST\n",
        "y_hat1 = feed_forward(x1,y1,syn,b)\n",
        "y_hat2 = feed_forward(x2,y2,syn,b)\n",
        "y_hat3 = feed_forward(x3,y3,syn,b)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7030299333006731\n",
            "0.7003970647199883\n",
            "0.6999291610175293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xS6VlmpYTzPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Compute backward propagation for the same network\n",
        "\n",
        "The backprop algorithm is derived from the goal of minimizing the error (or loss) function $\\epsilon = (y - \\hat{y})^2$.\n",
        "\n",
        "$\\epsilon = (y - \\sigma(h_2+b_2))^2$\n",
        "\n",
        "Via the chain rule, the derivative of the above is\n",
        "\n",
        "$\\frac{\\partial \\epsilon}{\\partial \\hat{y}} = 2(y-\\hat{y})\\sigma(h_2)$\n",
        "\n",
        "Let $\\alpha = 0.1$. Update the weights for $h_2$ and $h_1$ via back propagation so that $h_2$ = $h_2 + \\alpha \\frac{\\partial \\epsilon}{\\partial \\hat{y}}$ and $h_1 = h_1 + \\alpha \\frac{\\partial \\epsilon}{\\partial h_2}$\n",
        "\n",
        "Also, let $\\sigma(x) = ReLU(x)$. As such, $\\sigma'(x) = 0$ when $x \\le 0$ and $\\sigma'(x) = 1$ when $x \\gt 0$.\n",
        "\n",
        "Check Case1: of [Brian Dolhansky](http://briandolhansky.com/blog/2013/9/27/artificial-neural-networks-backpropagation-part-4) for a more detailed explanation of the values in the back propagation.\n"
      ]
    },
    {
      "metadata": {
        "id": "E8j-_SXZyECK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cd9235ba-c7a8-4b4e-870b-b99c7c4562ec"
      },
      "cell_type": "code",
      "source": [
        "def feed_forward_and_back_propagate(X,y,syn,b): \n",
        "  # seed random numbers to make calculation\n",
        "  np.random.seed(42) \n",
        "  alpha = 0.1\n",
        "  for iter in range(10000):\n",
        "      # forward propagation\n",
        "      l0 = nonlin(np.dot(X,syn[0])+b[0])\n",
        "      l1 = nonlin(np.dot(l0,syn[1])+b[1])\n",
        "      l2 = nonlin(np.dot(l1,syn[2])+b[2])\n",
        "      l2_error = y-l2\n",
        " \n",
        "      l2_delta = l2_error * nonlin(l2, deriv =True)\n",
        "   \n",
        "      l2_delta = np.array(l2_delta)\n",
        "\n",
        "      l1_error = np.dot(l2_delta,syn[2])\n",
        "\n",
        "      l1_delta = l1_error * nonlin(l1, deriv = True)\n",
        "   \n",
        "      l1_delta = np.array(l1_delta)\n",
        "      \n",
        "      l0_error = np.dot(l1_delta,syn[1])\n",
        "      \n",
        "      l0_delta = l0_error*nonlin(l0,deriv = True)\n",
        "      \n",
        "      l0_delta = np.array(l0_delta)\n",
        "\n",
        "      syn[2]  += 0.1*np.dot(l1,l2_delta)\n",
        "\n",
        "      syn[1]  += 0.1*np.dot(l0,l1_delta)\n",
        "      \n",
        "      syn[0]  += 0.1*np.dot(X,l0_delta)\n",
        "  print (\"Output After Training:\")\n",
        "  print (l2)\n",
        "  return l2\n",
        "\n",
        "y_hat4 = feed_forward_and_back_propagate(x1,y1,syn,b)\n",
        "y_hat5 = feed_forward_and_back_propagate(x2,y2,syn,b)\n",
        "y_hat6 = feed_forward_and_back_propagate(x3,y3,syn,b)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output After Training:\n",
            "0.02447878663904724\n",
            "Output After Training:\n",
            "0.9756804877685157\n",
            "Output After Training:\n",
            "0.9831760324205627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aO4_BSFEHmQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Back propagation has improved our results significantly."
      ]
    },
    {
      "metadata": {
        "id": "PYmuA8VwJ4_y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Use MLPClassifier to train a dataset\n",
        "\n",
        "`X` is now a small dataset. Create an MLPClassifier from sklearn and train it on the `X` dataset, with `y` as the targets."
      ]
    },
    {
      "metadata": {
        "id": "Jcyi6Z16OGuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7cc7c4b0-b381-4d0f-f689-a0af95730080"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.row_stack([x1,x2,x3])\n",
        "Y = np.row_stack([y1,y2,y3])\n",
        "\n",
        "# MLP Classifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model = MLPClassifier(\n",
        "                    hidden_layer_sizes=(15, 2),\n",
        "                    activation='tanh',\n",
        "                    solver='lbfgs',\n",
        "                    alpha=1e-5,\n",
        "                    batch_size=1, \n",
        "                    learning_rate='adaptive',\n",
        "                    learning_rate_init=1,\n",
        "                    max_iter=200,\n",
        "                    shuffle=True,\n",
        "                    random_state=42,\n",
        "                    verbose=10,\n",
        "                    tol=1e-4 )\n",
        "model.fit(X,Y)\n",
        "predicted_y = model.predict(X)\n",
        "print (predicted_y)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "try:\n",
        "    print (\"Mean AUC Score - MLPClassifier: \",roc_auc_score(Y, predicted_y))\n",
        "except ValueError:\n",
        "    pass\n",
        "\n",
        "    \n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1]\n",
            "Mean AUC Score - MLPClassifier:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}