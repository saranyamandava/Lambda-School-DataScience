{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week7_ Model Tuning Assignment-2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/saranyamandava/Lambda-School-DataScience/blob/master/Week7__Model_Tuning_Assignment_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "j3-9qZ80euzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part One: K-fold Cross Validation\n",
        "\n",
        "The challenge of training machine learning models is to be able to make accurate predictions on previously unseen real-world data in spite of the fact that we only have a finite training dataset to learn from. \n",
        "\n",
        "One way of validating our model's quality-of-fit and avoiding overfitting/underfitting, is to use the test_train_split method like we did in the code challenge. With this method, the randomly selected test dataset can be used to evaluate how our model performs on data that it has not yet seen in the training process. However, there are downsides to this approach:\n",
        "\n",
        "*   We lose a valuable portion of data that we would prefer to be able to train on to serve as the test dataset. We would prefer to have both the testing and training datasets be as large as possible.\n",
        "*   With small datasets, measures of our model's quality using the test_train_split method often have a high variance. (We saw this behavior when we changed the random seed in the code challenge)\n",
        "\n",
        "We can reduce the severity of both of these drawbacks by using what is called K-fold Cross Validation:\n",
        "\n",
        "[Short Video Explaining K-Fold Cross Validation](https://www.youtube.com/watch?v=TIgfjmp-4BA)\n",
        "\n",
        "[How to Implement K-Fold Cross Validation on the Pima Indians Diabetes dataset](https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/)"
      ]
    },
    {
      "metadata": {
        "id": "8-xSRguyK0SS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DO THIS:\n",
        "\n",
        "**1)** Train a logistic regression model on the titanic dataset predicting survivors first using a 20-80% test_train_split and print the accuracy of your model using 5 different random seeds.\n",
        "\n",
        "**2)** Use 5-fold Cross Validation on the titanic dataset. Print out the accuracies from each of the 5 folds of the cross validation, then print the final mean and standard deviation of those cross validation accuracies. How do the accuracies on each of the inidvidual folds compare to the accuracies of the test_train_split approach? Is the variance in accuracies of the cross-validation approach higher or lower than the variance of the test_train_split approach? \n",
        "\n",
        "**3)** Try using 3-fold Cross Validation as well as 10-fold cross validation. How does the number of folds in the cross-validation process affect the outcome? How many folds should be used?\n",
        "\n",
        "---\n",
        "I would give you more boilerplate code here, but I don't want to make it too easy. The articles linked above should be sufficient for this purpose."
      ]
    },
    {
      "metadata": {
        "id": "kqwcuyA9K6dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1ff438b6-d0e0-4c2b-f4d2-d04dd88339cb"
      },
      "cell_type": "code",
      "source": [
        "##### YOUR CODE HERE ##### - Feel free to add code cells as necessary.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split,KFold,RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression,Ridge\n",
        "from itertools import chain, combinations\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# drop duplicate/analogous columns\n",
        "titanic = titanic.drop(['alive',\n",
        "                        'adult_male',\n",
        "                        'who',\n",
        "                        'class',\n",
        "                        'embark_town'], axis=1)\n",
        "\n",
        "# take care of missing data\n",
        "titanic['embarked'] = titanic['embarked'].fillna(method='ffill')\n",
        "titanic = titanic.drop(['deck'], axis=1)\n",
        "titanic['age'] = titanic['age'].fillna(method='ffill')\n",
        "titanic = titanic.drop_duplicates()\n",
        "\n",
        "for label in ['embarked','sex', 'alone']:\n",
        "    titanic[label] = LabelEncoder().fit_transform(titanic[label])\n",
        "\n",
        "embarked_one_hot = OneHotEncoder().fit_transform(titanic[['embarked']]).toarray()\n",
        "embarked = pd.DataFrame(embarked_one_hot, \n",
        "                        columns=['Southampton', 'Cherbourg', 'Queenstown'], \n",
        "                        dtype=np.int64)\n",
        "\n",
        "titanic = titanic.reset_index(drop=True)\n",
        "data_encoded = titanic.join([embarked])\n",
        "data_encoded = data_encoded.drop(['embarked'], axis=1)\n",
        "\n",
        "print (data_encoded.head())\n",
        "\n",
        "print(data_encoded.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived  pclass  sex   age  sibsp  parch     fare  alone  Southampton  \\\n",
            "0         0       3    1  22.0      1      0   7.2500      0            0   \n",
            "1         1       1    0  38.0      1      0  71.2833      0            1   \n",
            "2         1       3    0  26.0      0      0   7.9250      1            0   \n",
            "3         1       1    0  35.0      1      0  53.1000      0            0   \n",
            "4         0       3    1  35.0      0      0   8.0500      1            0   \n",
            "\n",
            "   Cherbourg  Queenstown  \n",
            "0          0           1  \n",
            "1          0           0  \n",
            "2          0           1  \n",
            "3          0           1  \n",
            "4          0           1  \n",
            "(833, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U5vsF5sh_r0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a02952fd-db09-4eae-eb32-09450a2da867"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "random_seed_values = [7,42,43,91,52]\n",
        "\n",
        "for random_seed in random_seed_values:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data_encoded.drop(['survived', 'Southampton'], axis=1), \n",
        "    data_encoded[['survived']], test_size=0.2, random_state=41)\n",
        "  model = LogisticRegression()\n",
        "  model.fit(x_train, y_train)\n",
        "  result = model.score(x_test, y_test)\n",
        "  print(\"Random Seed:\",random_seed,\"Accuracy: %.3f%% (%.3f%%)\" % (result.mean()*100.0, result.std()*100.0))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Random Seed:', 7, 'Accuracy: 79.641% (0.000%)')\n",
            "('Random Seed:', 42, 'Accuracy: 79.641% (0.000%)')\n",
            "('Random Seed:', 43, 'Accuracy: 79.641% (0.000%)')\n",
            "('Random Seed:', 91, 'Accuracy: 79.641% (0.000%)')\n",
            "('Random Seed:', 52, 'Accuracy: 79.641% (0.000%)')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VNczB1bfUs12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "365e85dc-db4a-48b6-ae88-762cf93a9d71"
      },
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "model = LogisticRegression()\n",
        "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 78.527% (3.188%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LkhesE3FUw2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "139de09b-c7e1-4c38-a4cd-818d6134ebc0"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold # import KFold\n",
        "X = np.array(data_encoded.drop(['survived', 'Southampton'], axis=1)) # create an array\n",
        "y = np.array(data_encoded['survived']) # Create another array\n",
        "\n",
        "splits = [5,3,10]\n",
        "for split in splits:\n",
        "    kf = KFold(n_splits=split) # Define the split - into folds specified \n",
        "    kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "    print(kf) \n",
        "    KFold(n_splits=split, random_state=42, shuffle=False)\n",
        "    train_index = []\n",
        "    test_index = []\n",
        "    sum = 0 \n",
        "    print (\"Number of Splits:\",split)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "      #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      Y_train, Y_test = y[train_index], y[test_index]\n",
        "      model = LogisticRegression()\n",
        "      model.fit(X_train, Y_train)\n",
        "      result = model.score(X_test, Y_test)\n",
        "      \n",
        "      print(\"Accuracy: %.3f%%\" % (result*100.0))\n",
        "      sum = sum +(result)\n",
        "    print (\"Average accuracy:\",(sum/split)*100)  "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=5, random_state=None, shuffle=False)\n",
            "('Number of Splits:', 5)\n",
            "Accuracy: 78.443%\n",
            "Accuracy: 78.443%\n",
            "Accuracy: 76.647%\n",
            "Accuracy: 75.301%\n",
            "Accuracy: 81.325%\n",
            "('Average accuracy:', 78.03188803116659)\n",
            "KFold(n_splits=3, random_state=None, shuffle=False)\n",
            "('Number of Splits:', 3)\n",
            "Accuracy: 77.698%\n",
            "Accuracy: 76.619%\n",
            "Accuracy: 77.978%\n",
            "('Average accuracy:', 77.43162870425681)\n",
            "KFold(n_splits=10, random_state=None, shuffle=False)\n",
            "('Number of Splits:', 10)\n",
            "Accuracy: 76.190%\n",
            "Accuracy: 80.952%\n",
            "Accuracy: 76.190%\n",
            "Accuracy: 79.518%\n",
            "Accuracy: 75.904%\n",
            "Accuracy: 78.313%\n",
            "Accuracy: 77.108%\n",
            "Accuracy: 74.699%\n",
            "Accuracy: 80.723%\n",
            "Accuracy: 79.518%\n",
            "('Average accuracy:', 77.91164658634537)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H4DQdwgKCzsa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "There is a noticeable increase in validation accuracy when we are increasing the number of  folds from 3 to 5. As the number of folds is increased, the model is trained on a larger proportion of the data, and so should benefit from this up to a certain point.\n",
        "\n",
        "The other trend is that as the folds increase, the proportion of the data used for validation decreases, and thus becomes less accurate as a statistical estimate of the model's ability to generalize to unseen data."
      ]
    },
    {
      "metadata": {
        "id": "1qRSmAPZo0Qr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part Two: Hyperparameter Tuning\n",
        "\n",
        "An important technique for improving the accuracy of a machine learning model is to undertake a process known as Hyperparameter Tuning or Hyperparameter Optimization. In order to understand this process, we first need to understand the difference between a model parameter and a model hyperparameter. \n",
        "\n",
        "### What is a model parameter?\n",
        "\n",
        "A model parameter is a value that is generated by fitting our model to training data and is key to generating predictions with that model. They are **internal** to our model and we often are trying to estimate them as best as possible when we train the algorithm. \n",
        "\n",
        "For example, the parameters of a linear regression model would be its intercept value as well as the coefficient values on each of the X variables. Estimates of these crucial values (parameters) are obtained by fitting to the training data, perfectly define the model, are internal to the model, and are key to generating predictions. They are model parameters in every sense. \n",
        "\n",
        "### What is a model hyperparameter?\n",
        "\n",
        "Hyperparameters are values that are key to how well our algorithm runs, yet are **external** to our model and cannot be estimated from the training process. They are more like settings for our algorithm which must be designated before it is run and impact its performance. Here is some further reading:\n",
        "\n",
        "[Hyperparamters explanation on Quora](https://www.quora.com/What-are-hyperparameters-in-machine-learning)\n",
        "\n",
        "[Jason Brownlee Article on the difference between Parameters and Hyperparameters](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)\n",
        "\n",
        "### How do we find the best hyperparameters?\n",
        "\n",
        "Since we can't learn the best hyperparameters for our model from the data, we essentially just pick values and see which ones lead to the highest accuracy. This can be a tedious and complex process especially for certain models like neural networks which can have dozens of hyperparameters. We will get you familiar with the process using a more simple logistic regression model. \n",
        "\n",
        "### How do you know what hyperparameters exist for your particular model? \n",
        "\n",
        "Most models/libraries have default hyperparameters that will be used if we don't specify them. In the model selection process you might try out multiple models on a dataset and see which one gets you the highest out-of-the-box performance, (using the default hyperparameters) and then pick a couple of the highest performing algorithms and attempt hyperparameter tuning on them to compare how different models benefit from this process. Once you have narrowed down the models that you would like to tune, a quick google search can tell you what hyperparameters exist for that algorithm. \n",
        "\n",
        "Often you can learn about potential hyperparameters by looking at the documentation for a given algorithm in a library, here's the documentation for sklearn's logistic regression, see if you can spot the hyperparameters:\n",
        "\n",
        "[scikit-learn logistic regression docs](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wADqKJAgSqgI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DO THIS: \n",
        "\n",
        "Lets hyperparameter tune our **titanic** predictions using 5-fold cross validation to compare the accuracy of our tuned models. \n",
        "\n",
        "### Manual Hyperparameter Tuning:\n",
        "\n",
        "For our assignment today we are going to tune the 'C value' also known as the 'regularization strength' of our logistic regression as well as 'penalty' of our logistic regression algorithm.\n",
        "\n",
        "Read up on the regularlization strength and penalty of a logistic regression function. What might be some good values to test out? Hint: Look at the parameter definitions on the sci-kit learn logistic regression documentation. \n",
        "\n",
        "[scikit-learn logistic regression docs](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
        "\n",
        "[Regularization in Logistic Regression](https://www.kdnuggets.com/2016/06/regularization-logistic-regression.html)\n",
        "\n",
        "Fit your model 5 different times using 5 different C values of your choosing. Which value gives the highest accuracy? \n",
        "\n",
        "There are only two penalty values that we can use. Evaluate the model two more times using each penalty once. Which penalty gives the highest accuracy?"
      ]
    },
    {
      "metadata": {
        "id": "UJujhJnetnr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        },
        "outputId": "a7e96354-1958-44e7-cf77-921d4a105a01"
      },
      "cell_type": "code",
      "source": [
        "# The sample code below uses the Pima Indans Diabetes Dataset. \n",
        "# Here we are setting the C value hyperparameter to 1 and the penalty hyperparameter to \"l1\". \n",
        "# You can designate your hyperparameters in a similar fashion.\n",
        "\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = np.array(data_encoded.drop(['survived', 'Southampton'], axis=1)) # create an array\n",
        "Y = np.array(data_encoded['survived'])\n",
        "num_instances = len(X)\n",
        "seed = 7\n",
        "c_values = [1,3,5,7,100]\n",
        "penality_values = ['l1','l2']\n",
        "high = 0\n",
        "pen = None\n",
        "c_val = 0\n",
        "for penality in penality_values:\n",
        "  for c in c_values:\n",
        "      print (\"Penality = \",penality)\n",
        "      print (\"C \",c) \n",
        "      kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
        "      model = LogisticRegression(C=c, penalty=penality) ##### This is the important line\n",
        "      results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
        "      print(results)\n",
        "      print (\"Accuracy:\",results.mean()*100)\n",
        "      print (\"\\n\")\n",
        "      accu = results.mean()*100\n",
        "      if (high < accu):\n",
        "        high = accu\n",
        "        pen = penality\n",
        "        c_val = c\n",
        "        \n",
        "print (\"penality with highest accuracy:\",high)\n",
        "print (\"Best Penality:\",pen)\n",
        "print (\"Best C val:\",c_val)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Penality = ', 'l1')\n",
            "('C ', 1)\n",
            "[0.77245509 0.77245509 0.76646707 0.75301205 0.80722892]\n",
            "('Accuracy:', 77.43236418728807)\n",
            "\n",
            "\n",
            "('Penality = ', 'l1')\n",
            "('C ', 3)\n",
            "[0.76646707 0.76646707 0.76646707 0.75903614 0.80722892]\n",
            "('Accuracy:', 77.31332515691508)\n",
            "\n",
            "\n",
            "('Penality = ', 'l1')\n",
            "('C ', 5)\n",
            "[0.77245509 0.76646707 0.75449102 0.77108434 0.81325301]\n",
            "('Accuracy:', 77.55501046100571)\n",
            "\n",
            "\n",
            "('Penality = ', 'l1')\n",
            "('C ', 7)\n",
            "[0.77245509 0.76646707 0.75449102 0.77108434 0.81325301]\n",
            "('Accuracy:', 77.55501046100571)\n",
            "\n",
            "\n",
            "('Penality = ', 'l1')\n",
            "('C ', 100)\n",
            "[0.77245509 0.76646707 0.75449102 0.77108434 0.80722892]\n",
            "('Accuracy:', 77.43452853329487)\n",
            "\n",
            "\n",
            "('Penality = ', 'l2')\n",
            "('C ', 1)\n",
            "[0.78443114 0.78443114 0.76646707 0.75301205 0.81325301]\n",
            "('Accuracy:', 78.03188803116659)\n",
            "\n",
            "\n",
            "('Penality = ', 'l2')\n",
            "('C ', 3)\n",
            "[0.77844311 0.77245509 0.76646707 0.76506024 0.79518072]\n",
            "('Accuracy:', 77.55212466632999)\n",
            "\n",
            "\n",
            "('Penality = ', 'l2')\n",
            "('C ', 5)\n",
            "[0.77844311 0.77245509 0.76646707 0.76506024 0.80120482]\n",
            "('Accuracy:', 77.67260659404084)\n",
            "\n",
            "\n",
            "('Penality = ', 'l2')\n",
            "('C ', 7)\n",
            "[0.78443114 0.76646707 0.76646707 0.76506024 0.80120482]\n",
            "('Accuracy:', 77.67260659404084)\n",
            "\n",
            "\n",
            "('Penality = ', 'l2')\n",
            "('C ', 100)\n",
            "[0.77245509 0.76646707 0.75449102 0.77108434 0.80722892]\n",
            "('Accuracy:', 77.43452853329487)\n",
            "\n",
            "\n",
            "('penality with highest accuracy:', 78.03188803116659)\n",
            "('Best Penality:', 'l2')\n",
            "('Best C val:', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aq8mXV2rbWCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### YOUR CODE HERE ##### - Feel free to add as many code cells as necessary."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrwljGvubkpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) Grid-Search Hyperparameter Tuning:\n",
        "\n",
        "Imagine that your algorithm has 12 different potential hyperparameters and each them can take on 5 different values. Lets say that it takes your laptop 4 seconds to fit each fold of cross validation. For each 5-fold cross-validation it would then take 20 seconds to fit your model and get an accuracy reading reported back. Now imagine that you want to test every possible combination of hyperparameters on your algorithm to get the absolute highest accuracy. You can see how this might become exceedingly tedious and time-consuming to perform by hand. Some hyperparameters (like the C value) have much more than 5 potential values, making hyperparameter tuning a huge task. \n",
        "\n",
        "It is for this reason that more advanced optimization techniques exist, one of which we will be exploring today called GridSearch.\n",
        "\n",
        "### What does GridSearch do?\n",
        "\n",
        "GridSearch takes a dictionary of all of the different hyperparameters that you want to test, and then feeds all of the different combinations through the algorithm for you and then reports back to you which one had the highest accuracy. Pretty slick right? \n",
        "\n",
        "Here is some boilerplate code you can reference to create your implementations:\n",
        "\n",
        "[Chris Albon Logistic Regression sklearn Hyperparameter Tuning with GridSearch](https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_grid_search/)"
      ]
    },
    {
      "metadata": {
        "id": "sb4F7GlnjIvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create logistic regression object\n",
        "\n",
        "logistic = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrrfWSJOey0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of all of the different penalty values that you want to test and save them to a variable called 'penalty'\n",
        "penalty = ['l1', 'l2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-m1rVmNwfbSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of all of the different C values that you want to test and save them to a variable called 'C'\n",
        "C = np.logspace(0,4,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hy-B_Wm3fz-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60d13ef0-90e1-43e7-d6df-d43723ac1454"
      },
      "cell_type": "code",
      "source": [
        "# Now that you have two lists each holding the different values that you want test, use the dict() function to combine them into a dictionary. \n",
        "# Save your new dictionary to the variable 'hyperparameters'\n",
        "# Print out the dictionary if you're curious as to what it euds up looking like.\n",
        "\n",
        "\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "print (hyperparameters)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'penalty': ['l1', 'l2'], 'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
            "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
            "       3.59381366e+03, 1.00000000e+04])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v619p6o4j9-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit your model using gridsearch\n",
        "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
        "best_model = clf.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aUuCQH4gdBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c785554-b9b2-4ac2-8f88-1130f20e83ec"
      },
      "cell_type": "code",
      "source": [
        "# Print the best penalty and C value from best_model.best_estimator_.get_params()\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Best Penalty:', 'l2')\n",
            "('Best C:', 1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IqG4tPaQkKgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "adfad754-4f62-4daf-8137-0c6c59869c0a"
      },
      "cell_type": "code",
      "source": [
        "# Print out all of the different combinations of your grid search values and their corresponding accuracies.\n",
        "# https://stackoverflow.com/questions/22155953/how-to-print-out-an-accuracy-score-for-each-combination-within-gridsearch\n",
        "\n",
        "from pprint import pprint\n",
        "#pprint(clf.grid_scores_)\n",
        "\n",
        "params, mean, std = [clf.cv_results_[key] for key in ['params', 'mean_test_score', 'std_test_score']]\n",
        "pty = [p['penalty'] for p in params]\n",
        "c = [p['C'] for p in params]\n",
        "\n",
        "gridsearch = pd.DataFrame([pd.Series(x) for x in [pty, c, mean, std]]).T\n",
        "gridsearch.columns = ['Penalty', 'C', 'Accuracy: Mean', 'Accuracy: Standard Deviation']\n",
        "\n",
        "gridsearch"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Penalty</th>\n",
              "      <th>C</th>\n",
              "      <th>Accuracy: Mean</th>\n",
              "      <th>Accuracy: Standard Deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.0243739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>l2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.779112</td>\n",
              "      <td>0.0271565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>l1</td>\n",
              "      <td>2.78256</td>\n",
              "      <td>0.773109</td>\n",
              "      <td>0.024509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l2</td>\n",
              "      <td>2.78256</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.0182685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l1</td>\n",
              "      <td>7.74264</td>\n",
              "      <td>0.77551</td>\n",
              "      <td>0.0229641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>l2</td>\n",
              "      <td>7.74264</td>\n",
              "      <td>0.777911</td>\n",
              "      <td>0.0240033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>l1</td>\n",
              "      <td>21.5443</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>l2</td>\n",
              "      <td>21.5443</td>\n",
              "      <td>0.77551</td>\n",
              "      <td>0.0229641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>l1</td>\n",
              "      <td>59.9484</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>l2</td>\n",
              "      <td>59.9484</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>l1</td>\n",
              "      <td>166.81</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>l2</td>\n",
              "      <td>166.81</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>l1</td>\n",
              "      <td>464.159</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>l2</td>\n",
              "      <td>464.159</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>l1</td>\n",
              "      <td>1291.55</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>l2</td>\n",
              "      <td>1291.55</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>l1</td>\n",
              "      <td>3593.81</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>l2</td>\n",
              "      <td>3593.81</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>l1</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>l2</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.77431</td>\n",
              "      <td>0.024157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Penalty        C Accuracy: Mean Accuracy: Standard Deviation\n",
              "0       l1        1        0.77431                    0.0243739\n",
              "1       l2        1       0.779112                    0.0271565\n",
              "2       l1  2.78256       0.773109                     0.024509\n",
              "3       l2  2.78256        0.77431                    0.0182685\n",
              "4       l1  7.74264        0.77551                    0.0229641\n",
              "5       l2  7.74264       0.777911                    0.0240033\n",
              "6       l1  21.5443        0.77431                     0.024157\n",
              "7       l2  21.5443        0.77551                    0.0229641\n",
              "8       l1  59.9484        0.77431                     0.024157\n",
              "9       l2  59.9484        0.77431                     0.024157\n",
              "10      l1   166.81        0.77431                     0.024157\n",
              "11      l2   166.81        0.77431                     0.024157\n",
              "12      l1  464.159        0.77431                     0.024157\n",
              "13      l2  464.159        0.77431                     0.024157\n",
              "14      l1  1291.55        0.77431                     0.024157\n",
              "15      l2  1291.55        0.77431                     0.024157\n",
              "16      l1  3593.81        0.77431                     0.024157\n",
              "17      l2  3593.81        0.77431                     0.024157\n",
              "18      l1    10000        0.77431                     0.024157\n",
              "19      l2    10000        0.77431                     0.024157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "DPIjCwgpJ_jC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c91910eb-ae18-4433-9bf9-5e7a5f0ab7d8"
      },
      "cell_type": "code",
      "source": [
        "best_params = best_model.best_estimator_.get_params()\n",
        "print('Best penalty: {}, Best C: {}'.format(best_params['penalty'], best_params['C']))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best penalty: l2, Best C: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IwOTSHaUkd8J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What hyperparameters give you the highest accuracy? Keep on testing diferent values and report the hyperparameters that give you the highest accuracy."
      ]
    },
    {
      "metadata": {
        "id": "knXPk9DCIr93",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The best C is 1.0 and best penality is 'l2'\n",
        "Let's add few more values to C and test this again inorder to find best C value."
      ]
    },
    {
      "metadata": {
        "id": "Oi1fXERUJl4_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "C = np.linspace(1, 150)\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "clf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n",
        "best_model = clf.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvCaKjvMJrCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aec0ba2-8083-4ac8-931f-01a9c28d7fac"
      },
      "cell_type": "code",
      "source": [
        "best_params = best_model.best_estimator_.get_params()\n",
        "print('Best penalty: {}, Best C: {}'.format(best_params['penalty'], best_params['C']))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best penalty: l2, Best C: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r-ctaux7qOzv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "Explore more advanced automated approaches to hyperparameter tuning. Try and implemenet a random search approach: \n",
        "\n",
        "[Random Search Hyperparameter Tuning](https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)\n",
        "\n",
        "Then try a Bayesian Optimization Approach:\n",
        "\n",
        "[Bayesian Optimization](https://thuijskens.github.io/2016/12/29/bayesian-optimisation/)\n",
        "\n",
        "[scikit-optimize](https://scikit-optimize.github.io/notebooks/bayesian-optimization.html)\n",
        "\n",
        "[optunity](http://optunity.readthedocs.io/en/latest/notebooks/notebooks/sklearn-automated-classification.html)\n",
        "\n",
        "You could also try writing a blog post to show how well you understand Cross Validation or Hyperparameter Tuning, both are key concepts to practicing machine learning and would be valuable to demonstrate proficency in.\n"
      ]
    },
    {
      "metadata": {
        "id": "9By8ac4ZqA9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31cc120d-6f91-4fff-f6fa-fa19d63f5d29"
      },
      "cell_type": "code",
      "source": [
        "#Random Search Hyperparameter Tuning\n",
        "# prepare a uniform distribution to sample for the alpha parameter\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "C = np.logspace(-1, 3, 1000)\n",
        "penalty = ['l1', 'l2']\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "# create and fit a ridge regression model, testing random alpha values\n",
        "model = LogisticRegression()\n",
        "\n",
        "rsearch =  RandomizedSearchCV(model, hyperparameters, n_iter=100, random_state=41)\n",
        "rsearch.fit(X, Y)\n",
        "print(rsearch.best_params_)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'penalty': 'l1', 'C': 0.1259215613694151}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3-SABmm9N2Fn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Random search finds even lower value of C. Let's try giving more values to C and test."
      ]
    },
    {
      "metadata": {
        "id": "678Rk6ALOBVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b36ee7c-7dd7-4c58-91ad-4c49863a0d24"
      },
      "cell_type": "code",
      "source": [
        "C = np.linspace(1, 200)\n",
        "penalty = ['l1', 'l2']\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "rsearch = RandomizedSearchCV(model, hyperparameters, n_iter=100, random_state=41)\n",
        "rsearch.fit(X, Y)\n",
        "print(rsearch.best_params_)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'penalty': 'l2', 'C': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LCKFYRGhOS-0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The C value obtained is close to the C value generated in grid search "
      ]
    },
    {
      "metadata": {
        "id": "rP4RCv-ZOiwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Bayesian Optimization**: This code is referred from https://github.com/thuijskens/bayesian-optimization/blob/master/python/gp.py "
      ]
    },
    {
      "metadata": {
        "id": "fI9yTmIvSTs1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Bayesian Optimization\n",
        "import sklearn.gaussian_process as gp\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def expected_improvement(x, gaussian_process, evaluated_loss, greater_is_better=False, n_params=1):\n",
        "    \"\"\" expected_improvement\n",
        "    Expected improvement acquisition function.\n",
        "    Arguments:\n",
        "    ----------\n",
        "        x: array-like, shape = [n_samples, n_hyperparams]\n",
        "            The point for which the expected improvement needs to be computed.\n",
        "        gaussian_process: GaussianProcessRegressor object.\n",
        "            Gaussian process trained on previously evaluated hyperparameters.\n",
        "        evaluated_loss: Numpy array.\n",
        "            Numpy array that contains the values off the loss function for the previously\n",
        "            evaluated hyperparameters.\n",
        "        greater_is_better: Boolean.\n",
        "            Boolean flag that indicates whether the loss function is to be maximised or minimised.\n",
        "        n_params: int.\n",
        "            Dimension of the hyperparameter space.\n",
        "    \"\"\"\n",
        "\n",
        "    x_to_predict = x.reshape(-1, n_params)\n",
        "\n",
        "    mu, sigma = gaussian_process.predict(x_to_predict, return_std=True)\n",
        "\n",
        "    if greater_is_better:\n",
        "        loss_optimum = np.max(evaluated_loss)\n",
        "    else:\n",
        "        loss_optimum = np.min(evaluated_loss)\n",
        "\n",
        "    scaling_factor = (-1) ** (not greater_is_better)\n",
        "\n",
        "    # In case sigma equals zero\n",
        "    with np.errstate(divide='ignore'):\n",
        "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
        "        expected_improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "        expected_improvement[sigma == 0.0] == 0.0\n",
        "\n",
        "    return -1 * expected_improvement\n",
        "\n",
        "\n",
        "def sample_next_hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
        "                               bounds=(0, 10), n_restarts=25):\n",
        "    \"\"\" sample_next_hyperparameter\n",
        "    Proposes the next hyperparameter to sample the loss function for.\n",
        "    Arguments:\n",
        "    ----------\n",
        "        acquisition_func: function.\n",
        "            Acquisition function to optimise.\n",
        "        gaussian_process: GaussianProcessRegressor object.\n",
        "            Gaussian process trained on previously evaluated hyperparameters.\n",
        "        evaluated_loss: array-like, shape = [n_obs,]\n",
        "            Numpy array that contains the values off the loss function for the previously\n",
        "            evaluated hyperparameters.\n",
        "        greater_is_better: Boolean.\n",
        "            Boolean flag that indicates whether the loss function is to be maximised or minimised.\n",
        "        bounds: Tuple.\n",
        "            Bounds for the L-BFGS optimiser.\n",
        "        n_restarts: integer.\n",
        "            Number of times to run the minimiser with different starting points.\n",
        "    \"\"\"\n",
        "    best_x = None\n",
        "    best_acquisition_value = 1\n",
        "    n_params = bounds.shape[0]\n",
        "\n",
        "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
        "\n",
        "        res = minimize(fun=acquisition_func,\n",
        "                       x0=starting_point.reshape(1, -1),\n",
        "                       bounds=bounds,\n",
        "                       method='L-BFGS-B',\n",
        "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
        "\n",
        "        if res.fun < best_acquisition_value:\n",
        "            best_acquisition_value = res.fun\n",
        "            best_x = res.x\n",
        "\n",
        "    return best_x\n",
        "\n",
        "\n",
        "def bayesian_optimisation(n_iters, sample_loss, bounds, x0=None, n_pre_samples=10,\n",
        "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7):\n",
        "    \"\"\" bayesian_optimisation\n",
        "    Uses Gaussian Processes to optimise the loss function `sample_loss`.\n",
        "    Arguments:\n",
        "    ----------\n",
        "        n_iters: integer.\n",
        "            Number of iterations to run the search algorithm.\n",
        "        sample_loss: function.\n",
        "            Function to be optimised.\n",
        "        bounds: array-like, shape = [n_params, 2].\n",
        "            Lower and upper bounds on the parameters of the function `sample_loss`.\n",
        "        x0: array-like, shape = [n_pre_samples, n_params].\n",
        "            Array of initial points to sample the loss function for. If None, randomly\n",
        "            samples from the loss function.\n",
        "        n_pre_samples: integer.\n",
        "            If x0 is None, samples `n_pre_samples` initial points from the loss function.\n",
        "        gp_params: dictionary.\n",
        "            Dictionary of parameters to pass on to the underlying Gaussian Process.\n",
        "        random_search: integer.\n",
        "            Flag that indicates whether to perform random search or L-BFGS-B optimisation\n",
        "            over the acquisition function.\n",
        "        alpha: double.\n",
        "            Variance of the error term of the GP.\n",
        "        epsilon: double.\n",
        "            Precision tolerance for floats.\n",
        "    \"\"\"\n",
        "\n",
        "    x_list = []\n",
        "    y_list = []\n",
        "\n",
        "    n_params = bounds.shape[0]\n",
        "\n",
        "    if x0 is None:\n",
        "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
        "            x_list.append(params)\n",
        "            y_list.append(sample_loss(params))\n",
        "    else:\n",
        "        for params in x0:\n",
        "            x_list.append(params)\n",
        "            y_list.append(sample_loss(params))\n",
        "\n",
        "    xp = np.array(x_list)\n",
        "    yp = np.array(y_list)\n",
        "\n",
        "    # Create the GP\n",
        "    if gp_params is not None:\n",
        "        model = gp.GaussianProcessRegressor(**gp_params)\n",
        "    else:\n",
        "        kernel = gp.kernels.Matern()\n",
        "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
        "                                            alpha=alpha,\n",
        "                                            n_restarts_optimizer=10,\n",
        "                                            normalize_y=True)\n",
        "\n",
        "    for n in range(n_iters):\n",
        "\n",
        "        model.fit(xp, yp)\n",
        "\n",
        "        # Sample next hyperparameter\n",
        "        if random_search:\n",
        "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
        "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
        "            next_sample = x_random[np.argmax(ei), :]\n",
        "        else:\n",
        "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
        "\n",
        "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
        "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
        "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
        "\n",
        "        # Sample loss for new set of parameters\n",
        "        cv_score = sample_loss(next_sample)\n",
        "\n",
        "        # Update lists\n",
        "        x_list.append(next_sample)\n",
        "        y_list.append(cv_score)\n",
        "\n",
        "        # Update xp and yp\n",
        "        xp = np.array(x_list)\n",
        "        yp = np.array(y_list)\n",
        "\n",
        "    return xp, yp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mma5o2D4PEAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_loss(params):\n",
        "    C = params[0]\n",
        "    penalty = 'l1' if params[1] < (bounds[1,1]//2) else 'l2'\n",
        "    \n",
        "    model = LogisticRegression(C=C, penalty=penalty)\n",
        "    \n",
        "    return cross_val_score(model,\n",
        "                           X=X,\n",
        "                           y=Y,\n",
        "                           cv=5).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvqZo16OPP_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_iters = 10\n",
        "bounds = np.array([[0, 10], [0, 1]])\n",
        "hyperparameters, scores = bayesian_optimisation(n_iters, sample_loss, bounds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K499zKRQPqsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5162f14-906c-4337-f02f-6b34ca92af4a"
      },
      "cell_type": "code",
      "source": [
        "best_ix = np.argmax(scores)\n",
        "print(best_ix)\n",
        "best_C = hyperparameters[best_ix,0]\n",
        "best_penalty = 'l1' if hyperparameters[best_ix,1] < 0.5 else 'l2'\n",
        "print('Best penalty: {}, Best C: {}'.format(best_penalty, best_C))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "Best penalty: l2, Best C: 0.78963598403\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}